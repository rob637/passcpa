Software testing follows a progression. Each type serves a different purpose, and skipping stages introduces risk. Let's walk through them. <break time='1s'/> Unit testing is first. Developers test individual components or modules in isolation. Does this single function work as coded? Unit tests are automated, run frequently, and catch basic coding errors early. <break time='0.8s'/> Integration testing comes next. You combine components and test that they work together. Module A passes data to Module B. Does the interface work? Do the components integrate correctly? Integration testing catches interface problems and data passing issues. <break time='0.8s'/> System testing tests the complete system as a whole. Does the entire application function correctly from end to end? This includes functional testing against requirements, performance testing under load, and security testing for vulnerabilities. <break time='0.8s'/> User acceptance testing, or UAT, is performed by actual business users. Does the system meet business needs? Can users accomplish their real-world tasks? UAT validates that we built the right thing, not just that we built it right. <break time='1s'/> Regression testing is performed whenever changes are made. It verifies that new changes haven't broken existing functionality. You re-run previous tests to ensure the system still works as it did before. <break time='1s'/> Who performs each type? <break time='0.5s'/> Developers do unit and often integration testing. Independent QA teams do system testing. Business users do UAT. This segregation of duties is important because developers might miss their own errors. <break time='0.8s'/> Exam scenarios often involve testing being skipped or performed improperly. If UAT is skipped, the risk is that the system doesn't meet business needs. If regression testing is skipped, the risk is that changes introduce new defects. <break time='0.5s'/> The auditor verifies that testing is performed at each level by appropriate personnel with documented results.