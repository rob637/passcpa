// ISC Depth Questions - Batch 6
// Focus: ISC-II (Security advanced), ISC-IV (SOC/Systems), ISC-V (Emerging Tech)
// Difficulty: balanced

import { Question } from '../../../types';

export const ISC_QUESTIONS_DEPTH_6: Question[] = [
  {
    id: 'isc-d6-001',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Social Engineering Attacks',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'Social engineering attacks exploit:',
    options: [
      'Software vulnerabilities only',
      'Human psychology and trust — manipulating people into divulging confidential information, granting access, or performing actions through techniques like phishing, pretexting, baiting, and tailgating',
      'Only physical security weaknesses',
      'Database configuration errors',
    ],
    correctAnswer: 1,
    explanation: 'Social Engineering: Types: (1) Phishing: fraudulent emails/messages that appear to come from trusted sources — tricks users into clicking malicious links, entering credentials, or downloading malware. Variants: spear phishing (targeted), whaling (executives), vishing (voice/phone), smishing (SMS). (2) Pretexting: creating a fabricated scenario to trick the victim (e.g., posing as IT support, a vendor, or a bank). (3) Baiting: leaving malware-infected USB drives or offering free downloads. (4) Tailgating/Piggybacking: following authorized personnel through secured doors without authentication. (5) Quid pro quo: offering something (tech support, prizes) in exchange for information. (6) Business Email Compromise (BEC): impersonating executives to authorize wire transfers or sensitive data disclosure. Defense: (1) Security awareness training (most effective). (2) Phishing simulations. (3) Email security tools (SPF, DKIM, DMARC). (4) Verification procedures for sensitive requests. (5) Physical security (badges, mantraps). CPA relevance: social engineering is the #1 attack vector — understanding it is critical for assessing fraud risk and IT controls.',
    reference: 'NIST SP 800-61; SANS',
  },
  {
    id: 'isc-d6-002',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-IV',
    topicId: 'isc-soc',
    topic: 'SOC Reports',
    subtopic: 'Trust Services Criteria — Processing Integrity',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'The "Processing Integrity" criterion in a SOC 2 report relates to:',
    options: [
      'Data encryption only',
      'Whether system processing is complete, valid, accurate, timely, and authorized — ensuring that data is processed correctly and outputs reflect the intended purpose without unauthorized or erroneous modifications',
      'Physical security of servers',
      'Employee background checks',
    ],
    correctAnswer: 1,
    explanation: 'Trust Services Criteria — Processing Integrity (PI): System processing is complete, valid, accurate, timely, and authorized to meet the entity\'s objectives. PI criteria examples: (1) PI1.1: The entity implements policies and procedures for systems processing (input, processing, output) to result in products/services that meet specifications. (2) Input controls: validation, authorization, completeness checks (batch totals, record counts, hash totals). (3) Processing controls: error handling, exception processing, reconciliation of intermediary processing output. (4) Output controls: distribution, balancing, reconciliation to input, review of output for reasonableness. Common PI controls: (1) Data validation rules (format, range, existence, reasonableness checks). (2) Automated reconciliation between systems. (3) Error handling and correction procedures. (4) Audit trails for all transactions. (5) Separation of input/processing/output functions. Relevance: directly tied to financial data accuracy — PI failures can lead to material misstatements. Often included in SOC 2 reports for organizations processing financial transactions.',
    reference: 'AICPA Trust Services Criteria 2017; SOC 2',
  },
  {
    id: 'isc-d6-003',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-V',
    topicId: 'isc-emerging',
    topic: 'Emerging Technologies',
    subtopic: 'Big Data Analytics',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'Big data is commonly characterized by the "3 Vs":',
    options: [
      'Value, Virtue, Vision',
      'Volume (large amounts of data), Velocity (speed of data generation/processing), and Variety (different types of data — structured, semi-structured, unstructured) — additional Vs include Veracity (data quality) and Value',
      'Vendor, Version, Validation',
      'Virtual, Visual, Vocal',
    ],
    correctAnswer: 1,
    explanation: 'Big Data — The Vs: (1) Volume: massive scale — terabytes to petabytes. Traditional databases cannot handle. (2) Velocity: speed at which data is generated and must be processed (real-time streams, IoT data, social media). (3) Variety: structured (databases, spreadsheets), semi-structured (JSON, XML, emails), unstructured (text, images, video, audio). (4) Veracity (4th V): data quality, accuracy, and trustworthiness. (5) Value (5th V): business insights derived from analysis. Big data technologies: Hadoop (distributed storage/processing), Spark (fast in-memory processing), NoSQL databases (MongoDB, Cassandra), data lakes (raw storage for all data types), cloud platforms (AWS, Azure, GCP). Accounting/Audit applications: (1) Full population analysis (100% transaction testing). (2) Predictive analytics for fraud detection. (3) Customer behavior analysis. (4) Risk assessment. (5) Real-time financial monitoring. Challenges: data privacy, storage costs, skill gaps, data governance, analytical tool selection.',
    reference: 'AICPA Data Analytics; Gartner',
  },
  {
    id: 'isc-d6-004',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-I',
    topicId: 'isc-governance',
    topic: 'IT Governance and Risk',
    subtopic: 'Change Management Controls',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'IT change management controls ensure that:',
    options: [
      'Changes are made immediately without documentation',
      'All changes to IT systems are properly requested, reviewed, approved, tested, and documented before implementation — preventing unauthorized modifications that could compromise system integrity or financial data accuracy',
      'Only the CEO approves IT changes',
      'Changes are only made annually',
    ],
    correctAnswer: 1,
    explanation: 'IT Change Management: Process steps: (1) Change request (RFC): documented request describing the change, justification, risk assessment, rollback plan. (2) Change review: Change Advisory Board (CAB) or designated authority evaluates risk, impact, and priority. (3) Approval: appropriate level of authorization based on risk/impact (standard, normal, emergency classifications). (4) Testing: test in a non-production environment (QA/staging). User acceptance testing (UAT) for significant changes. (5) Implementation: scheduled deployment with rollback plan. Change window: defined period for deployments (e.g., off-peak hours). (6) Post-implementation review: verify the change achieved its objectives, no adverse effects. (7) Documentation: complete audit trail (who, what, when, why, approval evidence). Types: standard (pre-approved, low risk), normal (requires review), emergency (expedited — but still documented retrospectively). CPA relevance: change management is one of the most frequently tested ITGCs — weak change controls = unauthorized program modifications = potential financial statement misstatement.',
    reference: 'ITIL Change Management; COBIT 2019 BAI06',
  },
  {
    id: 'isc-d6-005',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Data Loss Prevention (DLP)',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'Data Loss Prevention (DLP) solutions protect against:',
    options: [
      'Only physical theft of hardware',
      'Unauthorized transmission, copying, or exposure of sensitive data — by monitoring and controlling data in motion (network traffic), data at rest (stored data), and data in use (endpoint activities) based on content inspection and policy rules',
      'All types of malware',
      'System performance degradation',
    ],
    correctAnswer: 1,
    explanation: 'DLP (Data Loss Prevention): Three states of data: (1) Data in motion: monitored as it traverses the network (email, web uploads, file transfers, messaging). DLP inspects content and blocks/quarantines/alerts on policy violations. (2) Data at rest: scans stored data (file servers, databases, cloud storage, endpoints) to identify sensitive data in unauthorized locations. (3) Data in use: monitors endpoint activities (copy/paste, screen capture, USB transfers, printing). DLP capabilities: (1) Content inspection: keyword matching, regular expressions (SSN, credit card patterns), fingerprinting (exact data matching), machine learning classification. (2) Context analysis: sender/recipient, file type, destination, time of day. (3) Policy actions: block, encrypt, quarantine, alert, log, allow with warning. Deployment: network DLP (appliance/gateway), endpoint DLP (agent-based), cloud DLP (CASB-integrated), email DLP. Use cases: PCI DSS (prevent cardholder data leakage), HIPAA (PHI protection), intellectual property protection, insider threat mitigation. CPA relevance: DLP is a key control for protecting financial data confidentiality and regulatory compliance.',
    reference: 'NIST SP 800-171; Gartner DLP',
  },
  {
    id: 'isc-d6-006',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-III',
    topicId: 'isc-data',
    topic: 'Data Management',
    subtopic: 'Relational Database Concepts',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'In a relational database, a "primary key" is:',
    options: [
      'A password for database access',
      'A column (or set of columns) that uniquely identifies each row in a table — no two rows can have the same primary key value, and it cannot be NULL, ensuring data integrity and enabling relationships between tables',
      'The first column in any table',
      'A backup encryption key',
    ],
    correctAnswer: 1,
    explanation: 'Relational Database Key Concepts: (1) Primary key: uniquely identifies each row. Must be unique, must not be NULL (entity integrity). Can be a single column or composite (multiple columns). (2) Foreign key: column in one table that references the primary key of another table. Enforces referential integrity (child records must have valid parent records). (3) Candidate key: any column(s) that could serve as the primary key (all unique). (4) Surrogate key: system-generated unique identifier (auto-increment, UUID). (5) Natural key: a real-world identifier used as the primary key (SSN, email). Database integrity rules: (1) Entity integrity: primary keys must be unique and not NULL. (2) Referential integrity: foreign keys must reference valid primary keys (or be NULL). (3) Domain integrity: column values must be within defined types/ranges. (4) User-defined integrity: business rules enforced by constraints, triggers, stored procedures. CPA relevance: understanding database structures helps assess data integrity controls, audit data extraction, and financial system design.',
    reference: 'Relational Database Theory; Codd',
  },
  {
    id: 'isc-d6-007',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-IV',
    topicId: 'isc-soc',
    topic: 'SOC Reports',
    subtopic: 'Subservice Organizations',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'When a service organization uses a subservice organization, the SOC report can present the subservice organization\'s services using:',
    options: [
      'Only the inclusive method',
      'Either the inclusive method (subservice organization\'s controls are included in the scope and tested) or the carve-out method (subservice organization\'s controls are excluded from scope, with management describing the nature of activities and their controls) — user entities need to understand which method is used',
      'Only the carve-out method',
      'No disclosure is required',
    ],
    correctAnswer: 1,
    explanation: 'SOC Report — Subservice Organization Methods: (1) Inclusive method: the subservice organization\'s relevant controls are INCLUDED in the SOC report\'s scope, description, and tested by the service auditor (or another auditor). Benefit: user entity gets one comprehensive report. Challenge: requires cooperation and access to the subservice organization. (2) Carve-out method: the subservice organization\'s controls are EXCLUDED from the SOC report scope. The report describes the nature of activities performed by the subservice organization and management\'s monitoring controls. User entity: must obtain a separate SOC report from the subservice organization OR gain assurance through other means. More common in practice. Implications for user entity auditors: (1) If carve-out: must understand what activities are performed by the subservice organization and obtain assurance (their own SOC report). (2) Must evaluate Complementary Subservice Organization Controls (CSOCs). (3) Determine if controls at the subservice organization are relevant to the user entity\'s financial reporting. CPA relevance: common scenario — financial institutions often use multiple layers of service providers.',
    reference: 'SSAE 18; AT-C 320.18-.20',
  },
  {
    id: 'isc-d6-008',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-V',
    topicId: 'isc-emerging',
    topic: 'Emerging Technologies',
    subtopic: 'Internet of Things (IoT)',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'The Internet of Things (IoT) presents accounting and auditing challenges because:',
    options: [
      'IoT devices are too expensive',
      'IoT devices generate massive volumes of data, expand the attack surface, often have limited security capabilities, and may automate transactions without direct human oversight — requiring new controls and audit approaches',
      'IoT only affects manufacturing',
      'IoT devices do not connect to networks',
    ],
    correctAnswer: 1,
    explanation: 'IoT in Accounting/Auditing Context: Challenges: (1) Data volume: sensors generate continuous data streams — traditional audit approaches may not handle the volume. (2) Security: many IoT devices have limited processing power → cannot run advanced security software. Default passwords, unpatched firmware, insecure communication protocols. (3) Expanded attack surface: every connected device is a potential entry point. (4) Automated transactions: IoT-triggered transactions (smart contracts, automated reordering) may occur without human approval. (5) Data integrity: ensuring IoT data is reliable for financial reporting (sensor accuracy, calibration). (6) Privacy: continuous data collection raises privacy concerns. Accounting applications: (1) Inventory management (RFID tracking, automated counts). (2) Asset management (GPS tracking, usage monitoring for depreciation). (3) Condition-based maintenance accounting. (4) Supply chain monitoring. (5) Insurance (usage-based policies). Audit considerations: (1) Understanding automated controls. (2) Testing IoT data reliability. (3) Evaluating cybersecurity of IoT infrastructure. (4) New types of audit evidence (sensor data).',
    reference: 'ISACA IoT Guide; NIST IR 8228',
  },
  {
    id: 'isc-d6-009',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-I',
    topicId: 'isc-governance',
    topic: 'IT Governance and Risk',
    subtopic: 'Third-Party Risk Management',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'Third-party risk management (TPRM) for IT vendors requires:',
    options: [
      'Only reviewing vendor marketing materials',
      'Due diligence before engagement, contractual security requirements, ongoing monitoring of vendor performance and security posture, incident notification obligations, and periodic reassessment — including right-to-audit clauses and SOC report reviews',
      'Accepting all vendor terms without review',
      'Only comparing vendor pricing',
    ],
    correctAnswer: 1,
    explanation: 'Third-Party Risk Management (TPRM): Lifecycle: (1) Risk assessment/due diligence: evaluate vendor\'s security practices, financial stability, compliance certifications (SOC 2, ISO 27001, PCI DSS), insurance, data handling practices, business continuity. (2) Contracting: include security requirements (encryption, access controls, incident notification), SLAs (availability, performance), right-to-audit clauses, data ownership provisions, confidentiality/NDA, insurance requirements, termination/transition provisions, subcontractor management. (3) Onboarding: access provisioning, integration testing, baseline performance metrics. (4) Ongoing monitoring: periodic review of SOC reports, security questionnaires (SIG), performance against SLAs, regulatory changes, financial health. (5) Incident management: vendor notification requirements (within X hours), coordination procedures. (6) Offboarding: data return/destruction, access revocation, transition planning. OCC guidance (banking): formal vendor management program required for banks using third-party providers. CPA relevance: understanding vendor risk is essential when financial data is processed by third parties — impacts audit procedures and controls reliance.',
    reference: 'OCC Bulletin 2013-29; NIST CSF',
  },
  {
    id: 'isc-d6-010',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Encryption — Symmetric vs. Asymmetric',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'The key difference between symmetric and asymmetric encryption is:',
    options: [
      'Symmetric encryption uses two keys',
      'Symmetric encryption uses one shared key for both encryption and decryption (fast, used for bulk data) — while asymmetric encryption uses a key pair (public key encrypts, private key decrypts), enabling secure key exchange and digital signatures',
      'Asymmetric encryption is always faster',
      'Symmetric encryption is only used for email',
    ],
    correctAnswer: 1,
    explanation: 'Symmetric vs. Asymmetric Encryption: Symmetric: (1) One shared secret key for encryption AND decryption. (2) Algorithms: AES (Advanced Encryption Standard — gold standard, 128/192/256-bit), 3DES (legacy), ChaCha20. (3) Advantages: fast, efficient for large data volumes. (4) Disadvantage: key distribution problem — how to securely share the key. (5) Use: bulk data encryption, database encryption, disk encryption (BitLocker), internal communications. Asymmetric: (1) Key pair: public key (shared openly) + private key (kept secret). (2) Algorithms: RSA (2048/4096-bit), ECC (Elliptic Curve — smaller keys, same security). (3) Two uses: (a) Encryption: public key encrypts → private key decrypts. (b) Digital signature: private key signs → public key verifies. (4) Advantage: solves key distribution (no need to share secret keys). (5) Disadvantage: slow (computationally intensive). Hybrid approach (TLS/SSL): use asymmetric encryption to exchange a symmetric session key → then use symmetric encryption for the session. CPA relevance: understanding encryption types is critical for evaluating data protection controls in audits.',
    reference: 'NIST SP 800-175B; FIPS 197 (AES)',
  },
  {
    id: 'isc-d6-011',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-III',
    topicId: 'isc-data',
    topic: 'Data Management',
    subtopic: 'Data Warehouse vs. Data Lake',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'A data warehouse differs from a data lake in that:',
    options: [
      'A data warehouse stores only unstructured data',
      'A data warehouse stores processed, structured data organized by subject (schema-on-write) for business intelligence and reporting — while a data lake stores raw data in its native format (schema-on-read) for flexible, exploratory analysis',
      'A data lake is always more expensive',
      'They are identical concepts',
    ],
    correctAnswer: 1,
    explanation: 'Data Warehouse vs. Data Lake: Data Warehouse: (1) Schema-on-write: data is structured and transformed before loading. (2) Stores processed, curated, structured data. (3) Optimized for queries and reporting (OLAP). (4) Subject-oriented, integrated, time-variant, nonvolatile (Inmon definition). (5) Star/snowflake schema (fact and dimension tables). (6) Users: business analysts, executives (BI/SQL). (7) Technologies: Snowflake, Amazon Redshift, Google BigQuery. Data Lake: (1) Schema-on-read: raw data stored in native format, structured at query time. (2) Stores ALL data types (structured, semi-structured, unstructured). (3) No predefined schema — maximum flexibility. (4) Users: data scientists, data engineers (Python, Spark, ML). (5) Technologies: Hadoop HDFS, AWS S3, Azure Data Lake. (6) Risk: "data swamp" if not properly governed. Data Lakehouse: hybrid — combines data lake flexibility with data warehouse performance and governance (Delta Lake, Apache Iceberg). CPA relevance: understanding data architecture helps assess data integrity for financial reporting, audit data sourcing, and analytics capabilities.',
    reference: 'Kimball; Inmon; Databricks',
  },
  {
    id: 'isc-d6-012',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-I',
    topicId: 'isc-governance',
    topic: 'IT Governance and Risk',
    subtopic: 'IT Risk Response Strategies',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'The four primary risk response strategies for IT risks are:',
    options: [
      'Detect, Correct, Prevent, Monitor',
      'Avoid (eliminate the risk), Mitigate (reduce likelihood/impact), Transfer (shift risk to another party through insurance or contracts), and Accept (acknowledge the risk when it is within tolerance)',
      'Plan, Do, Check, Act',
      'Identify, Classify, Report, Archive',
    ],
    correctAnswer: 1,
    explanation: 'IT Risk Response Strategies: (1) Avoid/Terminate: eliminate the activity that creates the risk. Example: decide not to offer online payments if the security risk is too high. Most effective but may sacrifice business opportunity. (2) Mitigate/Treat: implement controls to reduce likelihood or impact. Example: deploy firewall, encryption, access controls, training. Most common strategy. Controls: preventive (stop threats), detective (identify incidents), corrective (restore after incidents). (3) Transfer/Share: shift risk to a third party. Example: cyber insurance, outsourcing to a managed security provider (MSSP), contractual risk allocation. Note: operational risk can be transferred but regulatory responsibility usually cannot. (4) Accept/Tolerate: document the risk and accept it when the cost of mitigation exceeds the potential loss OR the risk is within the organization\'s risk appetite. Should include monitoring. Risk appetite: the level of risk an organization is willing to accept in pursuit of its objectives. Risk tolerance: the acceptable variation from the risk appetite. CPA relevance: understanding risk response informs audit procedures and assessments of management\'s IT risk management.',
    reference: 'COSO ERM 2017; NIST SP 800-39',
  },
  {
    id: 'isc-d6-013',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Identity and Access Management (IAM)',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'Identity and Access Management (IAM) encompasses:',
    options: [
      'Only password reset procedures',
      'The processes and technologies to manage digital identities throughout their lifecycle — including provisioning, authentication, authorization, access reviews, and de-provisioning, ensuring the right people have the right access at the right time',
      'Only badge access systems',
      'Social media account management',
    ],
    correctAnswer: 1,
    explanation: 'IAM (Identity and Access Management): Lifecycle: (1) Identity creation/provisioning: create accounts, assign roles/permissions per the principle of least privilege. HR-driven: tie to hiring process. (2) Authentication: verify identity. Methods: knowledge (password, PIN), possession (token, smart card, phone), inherence (biometrics — fingerprint, face, iris). MFA: combining 2+ factors. (3) Authorization: determine what authenticated users can access. Models: RBAC (Role-Based Access Control), ABAC (Attribute-Based), MAC (Mandatory), DAC (Discretionary). (4) Access review/recertification: periodic review of user access rights by data owners/managers. Typical frequency: quarterly for privileged access, semi-annually/annually for standard access. (5) De-provisioning: timely removal of access when no longer needed (termination, transfer, role change). Must be immediate for terminations. Key controls: (1) Unique user IDs (no shared accounts). (2) Password policies (complexity, expiration, history). (3) Privileged access management (PAM). (4) Segregation of duties enforcement. (5) Logging/monitoring of access events. CPA relevance: IAM is the most fundamental ITGC — directly impacts who can initiate, authorize, record, and process financial transactions.',
    reference: 'NIST SP 800-63; COBIT 2019 DSS05',
  },
  {
    id: 'isc-d6-014',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-IV',
    topicId: 'isc-soc',
    topic: 'SOC Reports',
    subtopic: 'SOC for Cybersecurity',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'A SOC for Cybersecurity examination provides:',
    options: [
      'The same report as a SOC 2',
      'An organization-wide assessment of the entity\'s cybersecurity risk management program — the report includes management\'s description of the cybersecurity risk management program and the CPA\'s opinion on its effectiveness using the AICPA\'s description criteria and the entity\'s selected control criteria',
      'Only penetration test results',
      'Regulatory certification for cybersecurity',
    ],
    correctAnswer: 1,
    explanation: 'SOC for Cybersecurity (AICPA): Purpose: entity-wide cybersecurity risk management examination. Key differences from SOC 2: (1) Scope: covers the ENTIRE entity\'s cybersecurity risk management program (not just a specific service/system). (2) Audience: general use — can be shared broadly (board, investors, regulators, public). (3) Report components: (a) Management\'s description of the cybersecurity risk management program (using AICPA description criteria). (b) Management\'s assertion about the program\'s effectiveness. (c) Practitioner\'s (CPA\'s) opinion on: description meets criteria AND controls are effective to achieve cybersecurity objectives. (4) Control criteria: entity selects appropriate criteria (NIST CSF, ISO 27001, AICPA TSC, or other suitable criteria). Benefits: (1) Board-level assurance on cybersecurity. (2) Stakeholder confidence. (3) Standardized reporting framework. (4) General-use distribution. Limitations: point-in-time or period-of-time (not continuous monitoring). CPA relevance: expanding role of CPAs in providing cybersecurity assurance — requires understanding of cybersecurity frameworks and risk assessment.',
    reference: 'AICPA SOC for Cybersecurity; AT-C 105',
  },
  {
    id: 'isc-d6-015',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-V',
    topicId: 'isc-emerging',
    topic: 'Emerging Technologies',
    subtopic: 'API Security',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'API (Application Programming Interface) security is critical in modern financial systems because:',
    options: [
      'APIs are never used in financial systems',
      'APIs enable data exchange between systems (banking, payment processing, accounting software) and are frequent attack targets — requiring authentication (OAuth, API keys), authorization, rate limiting, input validation, encryption, and monitoring to prevent data breaches',
      'APIs are only used for internal systems',
      'APIs automatically secure themselves',
    ],
    correctAnswer: 1,
    explanation: 'API Security: Why critical: APIs are the backbone of modern financial technology — open banking (PSD2), fintech integrations, ERP-to-ERP communication, mobile banking, payment gateways. They exchange sensitive financial data. OWASP API Security Top 10: (1) Broken Object Level Authorization. (2) Broken Authentication. (3) Broken Object Property Level Authorization. (4) Unrestricted Resource Consumption. (5) Broken Function Level Authorization. (6) Unrestricted Access to Sensitive Business Flows. (7) Server-Side Request Forgery. (8) Security Misconfiguration. (9) Improper Inventory Management. (10) Unsafe Consumption of APIs. Security controls: (1) Authentication: OAuth 2.0, JWT tokens, API keys, mutual TLS. (2) Authorization: RBAC/ABAC for API endpoints. (3) Rate limiting: prevent abuse and DoS attacks. (4) Input validation: prevent injection attacks. (5) Encryption: TLS for data in transit. (6) Logging and monitoring: track API usage, detect anomalies. (7) API gateway: centralized security, throttling, analytics. (8) API versioning and lifecycle management. CPA relevance: understanding API risks is essential when financial data flows through integrated systems and third-party services.',
    reference: 'OWASP API Security; NIST SP 800-204',
  },
  {
    id: 'isc-d6-016',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-I',
    topicId: 'isc-governance',
    topic: 'IT Governance and Risk',
    subtopic: 'COSO and IT Controls',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'The COSO Internal Control — Integrated Framework applies to IT controls through:',
    options: [
      'A separate IT-specific framework only',
      'The same five components (Control Environment, Risk Assessment, Control Activities, Information & Communication, Monitoring) and 17 principles — with control activities encompassing both IT general controls (ITGCs) and IT application controls that support financial reporting objectives',
      'Only the Control Environment component',
      'Annual IT audits only',
    ],
    correctAnswer: 1,
    explanation: 'COSO 2013 and IT Controls: Five components apply to IT: (1) Control Environment: tone at top for IT governance, IT organizational structure, competence of IT personnel, IT policies. (2) Risk Assessment: IT risk identification (cybersecurity, data integrity, availability), technology changes, vendor risks. (3) Control Activities: (a) IT General Controls: access management, change management, computer operations, program development. (b) IT Application Controls: input controls, processing controls, output controls. (c) Automated controls vs. IT-dependent manual controls. (4) Information & Communication: IT systems that capture and report financial data, data quality, system interfaces, communication of IT policies. (5) Monitoring: ongoing IT monitoring (SIEM, automated alerts), separate evaluations (IT audits, penetration tests), reporting deficiencies. Principle 11 specifically addresses technology: "The entity selects and develops general control activities over technology to support the achievement of objectives." SOX implications: management must evaluate design and effectiveness of IT controls as part of ICFR assessment. CPA relevance: understanding COSO\'s application to IT is fundamental for integrated audit approaches.',
    reference: 'COSO Internal Control 2013; PCAOB AS 2201',
  },
  {
    id: 'isc-d6-017',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Penetration Testing vs. Vulnerability Scanning',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'Penetration testing differs from vulnerability scanning because:',
    options: [
      'They are the same activity',
      'Penetration testing actively exploits discovered vulnerabilities to determine actual risk (simulates a real attack) — while vulnerability scanning passively identifies potential vulnerabilities without exploitation; both are important but serve different purposes',
      'Vulnerability scanning is more invasive',
      'Penetration testing uses only automated tools',
    ],
    correctAnswer: 1,
    explanation: 'Penetration Testing vs. Vulnerability Scanning: Vulnerability Scanning: (1) Automated tool-based. (2) Identifies POTENTIAL vulnerabilities (known CVEs, misconfigurations). (3) Non-exploitative (does not attempt to break in). (4) Broad coverage — scans many systems quickly. (5) Frequent: weekly/monthly/continuous. (6) Low risk to systems. (7) Primarily identifies vulnerabilities. Penetration Testing: (1) Skilled human testers (ethical hackers) + tools. (2) Actively EXPLOITS vulnerabilities to prove impact. (3) Attempts to chain vulnerabilities for deeper access. (4) Demonstrates actual risk (not just potential). (5) Less frequent: annually or after major changes. (6) Higher risk (controlled, with rules of engagement). (7) Proves business impact. Types: black box (no prior knowledge), white box (full access/documentation), gray box (partial knowledge). Scope: external (internet-facing), internal (inside the network), web application, social engineering, physical. Standards: PTES, OWASP Testing Guide, NIST SP 800-115. CPA relevance: understanding both testing approaches helps assess the entity\'s security testing program effectiveness.',
    reference: 'NIST SP 800-115; OWASP Testing Guide',
  },
  {
    id: 'isc-d6-018',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-III',
    topicId: 'isc-data',
    topic: 'Data Management',
    subtopic: 'Data Masking and Anonymization',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'Data masking (or data obfuscation) is used to:',
    options: [
      'Delete all sensitive data',
      'Replace sensitive data with realistic but fake values for use in non-production environments (testing, development, training) — preserving data format and relationships while protecting actual PII, financial data, and other confidential information',
      'Encrypt data for network transmission',
      'Back up data to the cloud',
    ],
    correctAnswer: 1,
    explanation: 'Data Masking/Anonymization Techniques: (1) Static data masking: irreversibly replace sensitive data in a copy (used for dev/test environments). Original data unchanged. (2) Dynamic data masking: real-time masking — sensitive data is masked on-the-fly during query results based on user privileges. Original data preserved. (3) Tokenization: replace sensitive data with non-sensitive tokens — a mapping table links tokens to original values (used in PCI DSS compliance for credit card numbers). (4) Anonymization: irreversibly transform data so individuals cannot be identified (GDPR: anonymized data is not "personal data"). Techniques: generalization, suppression, noise addition, k-anonymity. (5) Pseudonymization: replace identifiers with pseudonyms — reversible with the key (GDPR: pseudonymized data IS still personal data but gets lighter requirements). Use cases: (1) Testing environments (prevents production data exposure). (2) Training data for ML models. (3) Third-party data sharing. (4) GDPR/CCPA compliance. (5) Outsourcing (protect PII when sharing with offshore teams). CPA relevance: data masking controls are relevant when evaluating test environment security and privacy compliance.',
    reference: 'NIST SP 800-188; GDPR Art. 4(5)',
  },
  {
    id: 'isc-d6-019',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-IV',
    topicId: 'isc-soc',
    topic: 'SOC Reports',
    subtopic: 'Control Exceptions in SOC Reports',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'When a SOC report identifies control exceptions (deviations), the user entity auditor should:',
    options: [
      'Ignore the exceptions completely',
      'Assess whether the exceptions affect the relevant controls relied upon, determine if the service organization has implemented compensating controls, and consider whether additional audit procedures are needed at the user entity level',
      'Immediately issue a qualified opinion',
      'Discard the entire SOC report',
    ],
    correctAnswer: 1,
    explanation: 'Control Exceptions in SOC Reports: User entity auditor response: (1) Understand the nature and significance of exceptions: (a) Which controls had exceptions? (b) What was the exception rate? (c) Are the affected controls relevant to the user entity\'s financial reporting? (2) Assess impact: does the exception affect the user entity\'s specific transactions/processes? An exception in a control for Service X may not matter if the user entity only uses Service Y. (3) Evaluate compensating controls: the service organization may have other controls that mitigate the risk despite the exception. The user entity itself may have compensating controls. (4) Consider additional procedures: (a) Test complementary user entity controls more extensively. (b) Increase substantive testing for affected assertions. (c) Request additional information from the service organization. (d) Perform direct testing at the service organization (if contractual right exists). (5) Document conclusions: the auditor\'s assessment should be clearly documented in the audit workpapers. Modified SOC opinion: if the service auditor\'s opinion is modified (qualified/adverse) — significantly increases the user entity auditor\'s burden.',
    reference: 'AU-C 402; SSAE 18',
  },
  {
    id: 'isc-d6-020',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-V',
    topicId: 'isc-emerging',
    topic: 'Emerging Technologies',
    subtopic: 'Cloud Security — Shared Responsibility',
    difficulty: 'easy',
    skillLevel: 'Remembering and Understanding',
    question: 'The "shared responsibility model" in cloud computing means:',
    options: [
      'The cloud provider is responsible for everything',
      'Security responsibilities are divided between the cloud provider (security "of" the cloud — physical infrastructure, networking, hypervisor) and the customer (security "in" the cloud — data, access management, application configuration, encryption) — with divisions varying by service model (IaaS/PaaS/SaaS)',
      'The customer bears no responsibility',
      'Only the cloud provider handles data encryption',
    ],
    correctAnswer: 1,
    explanation: 'Cloud Shared Responsibility Model: Provider responsibilities ("Security OF the cloud"): (1) Physical security (data centers, hardware). (2) Network infrastructure. (3) Hypervisor/virtualization. (4) Host operating system (for PaaS/SaaS). (5) Availability (per SLAs). Customer responsibilities ("Security IN the cloud"): (1) Data classification and encryption. (2) Identity and access management (IAM). (3) Application security (for IaaS/PaaS). (4) Operating system patching (for IaaS). (5) Network security configuration (security groups, NACLs). (6) Compliance and regulatory requirements. Varies by model: IaaS → customer has most responsibility. PaaS → shared more equally. SaaS → customer responsible mainly for data and access. Examples: AWS (Shared Responsibility Model), Azure (Shared Responsibility), GCP (Shared Fate). CPA relevance: auditors must understand who controls what in a cloud environment to properly evaluate IT controls — the entity cannot fully delegate its control responsibilities by moving to the cloud.',
    reference: 'AWS Shared Responsibility; NIST SP 800-144',
  },
  {
    id: 'isc-d6-021',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-I',
    topicId: 'isc-governance',
    topic: 'IT Governance and Risk',
    subtopic: 'IT Audit Planning',
    difficulty: 'medium',
    skillLevel: 'Application',
    question: 'When planning the IT portion of a financial statement audit, the auditor should:',
    options: [
      'Test all IT controls regardless of relevance',
      'Identify IT applications and infrastructure supporting significant financial processes, assess IT risks, determine reliance on ITGCs, evaluate automated controls, and design test procedures for controls the auditor plans to rely upon',
      'Only interview the CIO',
      'Accept management\'s IT assessment without testing',
    ],
    correctAnswer: 1,
    explanation: 'IT Audit Planning Steps: (1) Understand the IT environment: identify key applications (ERP — SAP, Oracle, custom systems), databases, operating systems, network infrastructure, and cloud services supporting financial reporting. (2) Identify significant financial processes: which processes flow through which IT systems? Interactive data flows (interfaces, APIs, batch processes). (3) IT risk assessment: assess risks related to unauthorized access, program changes, data integrity, availability, cyber threats. Consider: complexity, changes during the period, history of issues. (4) Determine control reliance strategy: which automated controls will the auditor test? If relying on automated controls → must test related ITGCs. If ITGCs are weak → increased substantive testing/manual controls. (5) Scope ITGCs: access controls, change management, operations, for each in-scope application/system. (6) Design test procedures: walkthrough (design), testing (operating effectiveness — reperformance, inspection, observation, inquiry). (7) Evaluate IT specialists: need IT audit specialists? (CAS, CISA-qualified team members). CPA relevance: proper IT audit planning is required under AS 2110/AU-C 315 — IT risk assessment drives the entire audit strategy.',
    reference: 'AS 2110; AU-C 315',
  },
  {
    id: 'isc-d6-022',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-II',
    topicId: 'isc-security',
    topic: 'Information Security',
    subtopic: 'Security Information and Event Management (SIEM)',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'A SIEM (Security Information and Event Management) system:',
    options: [
      'Only stores backup data',
      'Aggregates and analyzes log data from across the IT environment in real-time — correlating events from multiple sources (firewalls, servers, applications, endpoints) to detect security threats, generate alerts, and support incident response and compliance reporting',
      'Only manages user passwords',
      'Replaces the need for an incident response team',
    ],
    correctAnswer: 1,
    explanation: 'SIEM (Security Information and Event Management): Core capabilities: (1) Log collection: aggregates logs from diverse sources — firewalls, IDS/IPS, servers, endpoints, applications, cloud services, databases, authentication systems. (2) Normalization: standardizes log formats for consistent analysis. (3) Correlation: analyzes events across multiple sources using predefined rules and patterns to identify complex threats that individual log sources cannot detect alone. (4) Real-time alerting: notifies security teams of potential incidents (configurable thresholds and severity levels). (5) Dashboards/reporting: visual representation of security posture, compliance status, incident trends. (6) Forensic analysis: historical log search for incident investigation. (7) Compliance reporting: automated reports for SOX, PCI DSS, HIPAA, GDPR requirements. Examples: Splunk, IBM QRadar, Microsoft Sentinel, Elastic Security. Next-gen capabilities: UEBA (User and Entity Behavior Analytics) — ML-based anomaly detection. SOAR (Security Orchestration, Automation, and Response) — automated incident response playbooks. CPA relevance: SIEM provides the monitoring/detective control layer that auditors evaluate — log retention, access monitoring, anomaly detection for financial systems.',
    reference: 'NIST SP 800-92; Gartner SIEM',
  },
  {
    id: 'isc-d6-023',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-III',
    topicId: 'isc-data',
    topic: 'Data Management',
    subtopic: 'Master Data Management (MDM)',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'Master Data Management (MDM) ensures:',
    options: [
      'All data is stored in one database',
      'A single, authoritative, consistent version of critical business data (customers, products, vendors, employees, chart of accounts) across all systems — eliminating duplicates and inconsistencies that can cause reporting errors and operational inefficiencies',
      'Data is deleted after 30 days',
      'Only IT has access to master data',
    ],
    correctAnswer: 1,
    explanation: 'MDM (Master Data Management): Master data: non-transactional data that defines business entities. Key domains: (1) Customer master: name, address, contacts, account numbers (critical for revenue recognition, AR). (2) Vendor/supplier master: payment terms, bank details (critical for AP, procurement fraud prevention). (3) Product/material master: descriptions, pricing, units of measure. (4) Employee master: HR data, payroll information. (5) Chart of accounts master: account structure, mapping, hierarchies. (6) Asset master: fixed asset records, depreciation parameters. MDM approaches: (1) Registry style: maintains links to source systems without moving data. (2) Consolidation: creates a golden record from multiple sources. (3) Coexistence: bi-directional sync between MDM hub and source systems. (4) Transaction hub: MDM is the authoritative source — all changes go through the hub. MDM governance: data stewards, data quality rules, workflow for create/change/delete, audit trails, approval processes. CPA relevance: weak MDM = duplicate vendors (fraud risk), inconsistent customer data (revenue misstatement), incorrect chart of accounts (misclassification). MDM controls are critical for financial statement accuracy.',
    reference: 'DAMA-DMBOK; Gartner MDM',
  },
  {
    id: 'isc-d6-024',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-IV',
    topicId: 'isc-soc',
    topic: 'SOC Reports',
    subtopic: 'Bridge Letters / Gap Periods',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'When a SOC report\'s coverage period does not align with the user entity\'s audit period (a "gap" exists), the user entity auditor should:',
    options: [
      'Ignore the gap entirely',
      'Evaluate the gap period by obtaining a bridge letter from the service organization, performing inquiry about changes to controls, reviewing the service organization\'s interim communications, considering other evidence, and possibly performing additional procedures to cover the gap',
      'Always request a new SOC report',
      'Issue a scope limitation on the audit',
    ],
    correctAnswer: 1,
    explanation: 'SOC Report Gap Period: Common situation: SOC 2 covers Jan-Sep, but audit period is Jan-Dec (3-month gap). Auditor options: (1) Bridge letter (management representation letter): service organization management provides written representations that no significant changes occurred to controls during the gap period and there were no control failures. Limited assurance — based on management assertions only. (2) Inquiry: ask the service organization about any significant changes to systems, controls, personnel, or incidents during the gap period. (3) Review interim communications: system status reports, incident notifications, change notifications. (4) Monitoring controls: evaluate the user entity\'s own monitoring of the service organization during the gap. (5) Roll-forward procedures: test key controls at the user entity that compensate for the unaudited gap period. (6) Consider the gap length: shorter gaps (1-3 months) are generally more acceptable. Longer gaps may require stronger compensating evidence. Best practice: coordinate with the service organization on SOC report timing to minimize gaps. AU-C 402 guidance: the auditor should consider the length of the gap and whether changes occurred.',
    reference: 'AU-C 402; SSAE 18',
  },
  {
    id: 'isc-d6-025',
    section: 'ISC',
    courseId: 'cpa',
    blueprintArea: 'ISC-V',
    topicId: 'isc-emerging',
    topic: 'Emerging Technologies',
    subtopic: 'Digital Twin Technology',
    difficulty: 'hard',
    skillLevel: 'Analysis',
    question: 'A "digital twin" in the context of enterprise systems is:',
    options: [
      'A backup server only',
      'A virtual replica of a physical asset, process, or system that receives real-time data to simulate, predict, and optimize performance — with accounting implications for asset valuation, predictive maintenance accruals, and real-time financial modeling',
      'A printed copy of digital documents',
      'A password recovery system',
    ],
    correctAnswer: 1,
    explanation: 'Digital Twin: Definition: a dynamic virtual model of a physical entity that mirrors its real-world counterpart through continuous data feeds (IoT sensors, operational data). Types: (1) Component twin: individual part (e.g., engine component). (2) Asset twin: complete equipment (e.g., manufacturing machine). (3) System twin: collection of assets working together (e.g., production line). (4) Process twin: entire business process (e.g., supply chain). Accounting/Business implications: (1) Asset valuation: real-time condition data may affect fair value estimates and impairment analysis. (2) Predictive maintenance: data-driven maintenance scheduling affects accrual estimates (warranty obligations, maintenance reserves). (3) Depreciation: usage-based depreciation using actual wear data vs. straight-line estimates. (4) Insurance: condition-based coverage and risk assessment. (5) Simulation: "what-if" analysis for capex decisions, capacity planning. (6) Audit evidence: real-time performance data as substantive evidence. Challenges: data reliability, integration with ERP systems, computational requirements, cybersecurity of connected assets. Industry adoption: manufacturing, energy, healthcare, construction, aerospace.',
    reference: 'Gartner Digital Twin; Deloitte',
  },
];
